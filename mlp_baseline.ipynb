{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron\n",
    "\n",
    "The baseline test described in the paper is that using an MLP. On the dataset, it achieved a 69.7% measured in AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import pairwise\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tinygrad import Tensor, nn\n",
    "from tinygrad.engine.lazy import LazyBuffer\n",
    "from tinygrad.helpers import colored, trange\n",
    "from tinygrad.tensor import Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n",
    "\n",
    "The methodology in the paper prescribes a 65/15/20 train/val/test set with 5 cross validation splits. The data is found in `ticdata2000.txt` and the pair of `ticeval2000.txt` and `tictgts2000.txt` (tic=The Insurance Company, eval=Evaluation/Test, tgts=Targets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str, delimiter: str = \"\\t\", has_target: bool = True):\n",
    "    data = np.loadtxt(file_path, delimiter=delimiter)\n",
    "    if has_target:\n",
    "        X, y = data[:, :-1], data[:, -1]\n",
    "        return X, y\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_nonbinary_columns(X: np.ndarray) -> np.ndarray:\n",
    "    for i in range(X.shape[1]):\n",
    "        unique_vals = np.unique(X[:, i])\n",
    "        if not np.array_equal(unique_vals, [0, 1]):\n",
    "            X[:, i] = (X[:, i] - np.mean(X[:, i])) / np.std(X[:, i])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/names.txt\", \"r\") as file:\n",
    "    feature_names = [line.strip() for line in file.readlines()]\n",
    "\n",
    "X_train, y_train = load_data(\"dataset/ticdata2000.txt\")\n",
    "X_train = normalize_nonbinary_columns(X_train)\n",
    "\n",
    "X_test = load_data(\"dataset/ticeval2000.txt\", has_target=False)\n",
    "X_test = normalize_nonbinary_columns(X_test)\n",
    "y_test = np.loadtxt(\"dataset/tictgts2000.txt\", delimiter=\"\\t\")\n",
    "\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.concatenate((y_train, y_test))\n",
    "\n",
    "num_samples = X_combined.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "X_shuffled = X_combined[indices]\n",
    "y_shuffled = y_combined[indices]\n",
    "\n",
    "train_end = int(0.65 * num_samples)\n",
    "val_end = int((0.65 + 0.15) * num_samples)\n",
    "\n",
    "X_train_new = X_shuffled[:train_end]\n",
    "y_train_new = y_shuffled[:train_end]\n",
    "X_val_new = X_shuffled[train_end:val_end]\n",
    "y_val_new = y_shuffled[train_end:val_end]\n",
    "X_test_new = X_shuffled[val_end:]\n",
    "y_test_new = y_shuffled[val_end:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "- 2 hidden layers:\n",
    "  - $l$ is the input size\n",
    "  - 1<sup>st</sup> hidden layer had $m_1l$ units where $1\\le m_1\\le 8$.\n",
    "  - 2<sup>nd</sup> hidden layer had $m_2l$ units where $1\\le m_2\\le 3$.\n",
    "- SELU Activation Function.\n",
    "- Batch Normalization after each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/blob/96aaa311c0251d24decb9dc5da4957b7c590af6f/torch/nn/modules/activation.py#L507\n",
    "class Selu(Function):\n",
    "    _alpha: float = 1.6732632423543772848170429916717\n",
    "    _lambda: float = 1.0507009873554804934193349852946\n",
    "\n",
    "    def forward(self, x: LazyBuffer) -> LazyBuffer:\n",
    "        alpha_buf = x.const_like(self._alpha)\n",
    "        lambda_buf = x.const_like(self._lambda)\n",
    "        self.ret = lambda_buf * LazyBuffer.where(\n",
    "            x >= 0, x, alpha_buf * ((x * (1 / math.log(2))).exp2() - 1)\n",
    "        )\n",
    "        return self.ret\n",
    "\n",
    "    def backward(self, grad_output: LazyBuffer) -> LazyBuffer:\n",
    "        alpha_buf = self.ret.const_like(self._alpha)\n",
    "        lambda_buf = self.ret.const_like(self._lambda)\n",
    "        dx = LazyBuffer.where(\n",
    "            self.ret >= 0,\n",
    "            lambda_buf,\n",
    "            lambda_buf * alpha_buf * (self.ret * (1 / math.log(2))).exp2(),\n",
    "        )\n",
    "        return dx * grad_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, l: int, m1: int = 4, m2: int = 2) -> None:\n",
    "        self.layers: List[Callable[[Tensor], Tensor]] = [\n",
    "            nn.Linear(l, m1 * l),\n",
    "            nn.BatchNorm(m1 * l),\n",
    "            Selu.apply,\n",
    "            nn.Linear(m1 * l, m2 * l),\n",
    "            nn.BatchNorm(m2 * l),\n",
    "            Selu.apply,\n",
    "            nn.Linear(m2 * l, 1),\n",
    "            Tensor.sigmoid,\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        return x.sequential(self.layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "- Evaluation metric was Area under the Curve (AUC).\n",
    "- Cross Entropy Loss.\n",
    "- AdamW optimizer.\n",
    "- Constant Learning Rate (What value?).\n",
    "- Trained with early stopping based on the performance of validation set.\n",
    "  - Stopping patience (# of epochs) was 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINED FOR 1, CURRENT LOSS IS: 0.5540088902157868\n",
      "TRAINED FOR 2, CURRENT LOSS IS: 0.5533869068351827\n",
      "TRAINED FOR 3, CURRENT LOSS IS: 0.5532376308238377\n",
      "TRAINED FOR 4, CURRENT LOSS IS: 0.5524331989849232\n",
      "TRAINED FOR 5, CURRENT LOSS IS: 0.5520848882917848\n",
      "TRAINED FOR 6, CURRENT LOSS IS: 0.5510731286593356\n",
      "TRAINED FOR 7, CURRENT LOSS IS: 0.550890680201025\n",
      "TRAINED FOR 8, CURRENT LOSS IS: 0.5504926108374384\n",
      "TRAINED FOR 9, CURRENT LOSS IS: 0.5502521105969381\n",
      "TRAINED FOR 10, CURRENT LOSS IS: 0.5499037999037999\n",
      "TRAINED FOR 11, CURRENT LOSS IS: 0.5495306098754374\n",
      "TRAINED FOR 12, CURRENT LOSS IS: 0.5496467134398169\n",
      "TRAINED FOR 13, CURRENT LOSS IS: 0.5502935761556451\n",
      "TRAINED FOR 14, CURRENT LOSS IS: 0.549862334345093\n",
      "TRAINED FOR 15, CURRENT LOSS IS: 0.5494062131993166\n",
      "TRAINED FOR 16, CURRENT LOSS IS: 0.5499535585742482\n",
      "TRAINED FOR 17, CURRENT LOSS IS: 0.549049609394437\n",
      "TRAINED FOR 18, CURRENT LOSS IS: 0.5486930055895574\n",
      "TRAINED FOR 19, CURRENT LOSS IS: 0.5488588678243851\n",
      "TRAINED FOR 20, CURRENT LOSS IS: 0.548535436466471\n",
      "TRAINED FOR 21, CURRENT LOSS IS: 0.548236884443781\n",
      "TRAINED FOR 22, CURRENT LOSS IS: 0.547830521968453\n",
      "TRAINED FOR 23, CURRENT LOSS IS: 0.5477144184040735\n",
      "TRAINED FOR 24, CURRENT LOSS IS: 0.547614901063177\n",
      "TRAINED FOR 25, CURRENT LOSS IS: 0.5478388150801945\n",
      "TRAINED FOR 26, CURRENT LOSS IS: 0.5476397803984011\n",
      "TRAINED FOR 27, CURRENT LOSS IS: 0.5479880910915393\n",
      "TRAINED FOR 28, CURRENT LOSS IS: 0.5477558839627805\n",
      "TRAINED FOR 29, CURRENT LOSS IS: 0.5468353485594865\n",
      "TRAINED FOR 30, CURRENT LOSS IS: 0.547059262576504\n",
      "TRAINED FOR 31, CURRENT LOSS IS: 0.5474573319400906\n",
      "TRAINED FOR 32, CURRENT LOSS IS: 0.5467441243303313\n",
      "TRAINED FOR 33, CURRENT LOSS IS: 0.5464123998606757\n",
      "TRAINED FOR 34, CURRENT LOSS IS: 0.5457074853626578\n",
      "TRAINED FOR 35, CURRENT LOSS IS: 0.5461553133966928\n",
      "TRAINED FOR 36, CURRENT LOSS IS: 0.546909986565159\n",
      "TRAINED FOR 37, CURRENT LOSS IS: 0.5451684330994675\n",
      "TRAINED FOR 38, CURRENT LOSS IS: 0.5441981390257252\n",
      "TRAINED FOR 39, CURRENT LOSS IS: 0.5441235010200527\n",
      "TRAINED FOR 40, CURRENT LOSS IS: 0.5450937950937952\n",
      "TRAINED FOR 41, CURRENT LOSS IS: 0.5464206929724171\n",
      "TRAINED FOR 42, CURRENT LOSS IS: 0.5473329352639698\n",
      "TRAINED FOR 43, CURRENT LOSS IS: 0.5472582972582973\n",
      "TRAINED FOR 44, CURRENT LOSS IS: 0.5478429616360652\n",
      "TRAINED FOR 45, CURRENT LOSS IS: 0.5468270554477451\n",
      "TRAINED FOR 46, CURRENT LOSS IS: 0.5465782620955035\n",
      "TRAINED FOR 47, CURRENT LOSS IS: 0.54584017515052\n",
      "TRAINED FOR 48, CURRENT LOSS IS: 0.5452928297755884\n",
      "TRAINED FOR 49, CURRENT LOSS IS: 0.5453177091108126\n",
      "TRAINED FOR 50, CURRENT LOSS IS: 0.546802176112521\n",
      "TRAINED FOR 51, CURRENT LOSS IS: 0.5463626411902274\n",
      "TRAINED FOR 52, CURRENT LOSS IS: 0.5471919523643662\n",
      "TRAINED FOR 53, CURRENT LOSS IS: 0.5472251248113318\n",
      "TRAINED FOR 54, CURRENT LOSS IS: 0.5471339005821765\n",
      "TRAINED FOR 55, CURRENT LOSS IS: 0.5457572440331061\n",
      "TRAINED FOR 56, CURRENT LOSS IS: 0.5467938830007796\n",
      "TRAINED FOR 57, CURRENT LOSS IS: 0.5459396924914166\n",
      "TRAINED FOR 58, CURRENT LOSS IS: 0.5467275381068485\n",
      "TRAINED FOR 59, CURRENT LOSS IS: 0.5458152958152958\n",
      "TRAINED FOR 60, CURRENT LOSS IS: 0.54554162312783\n",
      "TRAINED FOR 61, CURRENT LOSS IS: 0.5459396924914166\n",
      "TRAINED FOR 62, CURRENT LOSS IS: 0.5474822112753148\n",
      "TRAINED FOR 63, CURRENT LOSS IS: 0.5475568492809872\n",
      "TRAINED FOR 64, CURRENT LOSS IS: 0.5467938830007796\n",
      "TRAINED FOR 65, CURRENT LOSS IS: 0.5463377618550032\n",
      "TRAINED FOR 66, CURRENT LOSS IS: 0.5451103813172778\n",
      "TRAINED FOR 67, CURRENT LOSS IS: 0.5457987095918131\n",
      "TRAINED FOR 68, CURRENT LOSS IS: 0.5457655371448474\n",
      "TRAINED FOR 69, CURRENT LOSS IS: 0.5462880031845548\n",
      "TRAINED FOR 70, CURRENT LOSS IS: 0.5464041067489344\n",
      "TRAINED FOR 71, CURRENT LOSS IS: 0.5467855898890381\n",
      "TRAINED FOR 72, CURRENT LOSS IS: 0.5462714169610721\n",
      "TRAINED FOR 73, CURRENT LOSS IS: 0.5467938830007796\n",
      "TRAINED FOR 74, CURRENT LOSS IS: 0.5460640891675375\n",
      "TRAINED FOR 75, CURRENT LOSS IS: 0.5469846245708315\n",
      "TRAINED FOR 76, CURRENT LOSS IS: 0.5464538654193827\n",
      "TRAINED FOR 77, CURRENT LOSS IS: 0.5456577266922095\n",
      "TRAINED FOR 78, CURRENT LOSS IS: 0.5455913817982784\n",
      "TRAINED FOR 79, CURRENT LOSS IS: 0.5453757608930023\n",
      "TRAINED FOR 80, CURRENT LOSS IS: 0.5445547428306049\n",
      "TRAINED FOR 81, CURRENT LOSS IS: 0.5463709343019688\n",
      "TRAINED FOR 82, CURRENT LOSS IS: 0.5455996749100197\n",
      "TRAINED FOR 83, CURRENT LOSS IS: 0.5453425884460368\n",
      "TRAINED FOR 84, CURRENT LOSS IS: 0.5462133651788824\n",
      "TRAINED FOR 85, CURRENT LOSS IS: 0.5451684330994676\n",
      "TRAINED FOR 86, CURRENT LOSS IS: 0.5446045015010532\n",
      "TRAINED FOR 87, CURRENT LOSS IS: 0.5459562787148995\n",
      "TRAINED FOR 88, CURRENT LOSS IS: 0.5467938830007796\n",
      "TRAINED FOR 89, CURRENT LOSS IS: 0.5469265727886418\n",
      "TRAINED FOR 90, CURRENT LOSS IS: 0.5460723822792788\n",
      "TRAINED FOR 91, CURRENT LOSS IS: 0.545284536663847\n",
      "TRAINED FOR 92, CURRENT LOSS IS: 0.5459728649383822\n",
      "TRAINED FOR 93, CURRENT LOSS IS: 0.5447786568476224\n",
      "TRAINED FOR 94, CURRENT LOSS IS: 0.5440820354613458\n",
      "TRAINED FOR 95, CURRENT LOSS IS: 0.5438166558856214\n",
      "TRAINED FOR 96, CURRENT LOSS IS: 0.5439493456734836\n",
      "TRAINED FOR 97, CURRENT LOSS IS: 0.5441566734670183\n",
      "TRAINED FOR 98, CURRENT LOSS IS: 0.5442478976961735\n",
      "TRAINED FOR 99, CURRENT LOSS IS: 0.5437171385447248\n",
      "TRAINED FOR 100, CURRENT LOSS IS: 0.5446459670597602\n",
      "TRAINED FOR 101, CURRENT LOSS IS: 0.5446708463949843\n",
      "TRAINED FOR 102, CURRENT LOSS IS: 0.5456991922509165\n",
      "TRAINED FOR 103, CURRENT LOSS IS: 0.5456908991391749\n",
      "TRAINED FOR 104, CURRENT LOSS IS: 0.5444635186014497\n",
      "TRAINED FOR 105, CURRENT LOSS IS: 0.5438995870030353\n",
      "TRAINED FOR 106, CURRENT LOSS IS: 0.5437171385447248\n",
      "TRAINED FOR 107, CURRENT LOSS IS: 0.543294189845914\n",
      "TRAINED FOR 108, CURRENT LOSS IS: 0.543700552321242\n",
      "TRAINED FOR 109, CURRENT LOSS IS: 0.5434517589690003\n",
      "TRAINED FOR 110, CURRENT LOSS IS: 0.5441400872435356\n",
      "TRAINED FOR 111, CURRENT LOSS IS: 0.5433688278515865\n",
      "TRAINED FOR 112, CURRENT LOSS IS: 0.5444966910484152\n",
      "TRAINED FOR 113, CURRENT LOSS IS: 0.5439576387852251\n",
      "TRAINED FOR 114, CURRENT LOSS IS: 0.5440156905674147\n",
      "TRAINED FOR 115, CURRENT LOSS IS: 0.5454255195634506\n",
      "TRAINED FOR 116, CURRENT LOSS IS: 0.5467690036655555\n",
      "TRAINED FOR 117, CURRENT LOSS IS: 0.5468353485594865\n",
      "TRAINED FOR 118, CURRENT LOSS IS: 0.5463128825197792\n",
      "TRAINED FOR 119, CURRENT LOSS IS: 0.5454006402282264\n",
      "TRAINED FOR 120, CURRENT LOSS IS: 0.5460060373853478\n",
      "TRAINED FOR 121, CURRENT LOSS IS: 0.5467938830007796\n",
      "TRAINED FOR 122, CURRENT LOSS IS: 0.5467026587716243\n",
      "TRAINED FOR 123, CURRENT LOSS IS: 0.5474822112753148\n",
      "TRAINED FOR 124, CURRENT LOSS IS: 0.5474324526048664\n",
      "TRAINED FOR 125, CURRENT LOSS IS: 0.5476895390688494\n",
      "TRAINED FOR 126, CURRENT LOSS IS: 0.5470924350234695\n",
      "TRAINED FOR 127, CURRENT LOSS IS: 0.546354348078486\n",
      "TRAINED FOR 128, CURRENT LOSS IS: 0.5462548307375894\n",
      "TRAINED FOR 129, CURRENT LOSS IS: 0.5466694863246587\n",
      "TRAINED FOR 130, CURRENT LOSS IS: 0.5451352606525021\n",
      "TRAINED FOR 131, CURRENT LOSS IS: 0.5447123119536912\n",
      "TRAINED FOR 132, CURRENT LOSS IS: 0.5441815528022425\n",
      "TRAINED FOR 133, CURRENT LOSS IS: 0.5433522416281037\n",
      "TRAINED FOR 134, CURRENT LOSS IS: 0.5435512763098971\n",
      "TRAINED FOR 135, CURRENT LOSS IS: 0.5452016055464332\n",
      "TRAINED FOR 136, CURRENT LOSS IS: 0.5458567613740029\n",
      "TRAINED FOR 137, CURRENT LOSS IS: 0.5448781741885191\n",
      "TRAINED FOR 138, CURRENT LOSS IS: 0.5436176212038281\n",
      "TRAINED FOR 139, CURRENT LOSS IS: 0.5443474150370702\n",
      "TRAINED FOR 140, CURRENT LOSS IS: 0.5441898459139838\n",
      "TRAINED FOR 141, CURRENT LOSS IS: 0.5453094159990712\n",
      "TRAINED FOR 142, CURRENT LOSS IS: 0.5445215703836395\n",
      "TRAINED FOR 143, CURRENT LOSS IS: 0.5447786568476224\n",
      "TRAINED FOR 144, CURRENT LOSS IS: 0.5439493456734836\n",
      "TRAINED FOR 145, CURRENT LOSS IS: 0.5449279328589673\n",
      "TRAINED FOR 146, CURRENT LOSS IS: 0.5452098986581746\n",
      "TRAINED FOR 147, CURRENT LOSS IS: 0.5442976563666219\n",
      "TRAINED FOR 148, CURRENT LOSS IS: 0.5441566734670183\n",
      "TRAINED FOR 149, CURRENT LOSS IS: 0.5443805874840358\n",
      "TRAINED FOR 150, CURRENT LOSS IS: 0.545690899139175\n",
      "TRAINED FOR 151, CURRENT LOSS IS: 0.5457074853626578\n",
      "TRAINED FOR 152, CURRENT LOSS IS: 0.5449528121941914\n",
      "TRAINED FOR 153, CURRENT LOSS IS: 0.5457987095918131\n",
      "TRAINED FOR 154, CURRENT LOSS IS: 0.5447786568476224\n",
      "TRAINED FOR 155, CURRENT LOSS IS: 0.5450937950937951\n",
      "TRAINED FOR 156, CURRENT LOSS IS: 0.5445713290540878\n",
      "TRAINED FOR 157, CURRENT LOSS IS: 0.5443557081488116\n",
      "TRAINED FOR 158, CURRENT LOSS IS: 0.5440073974556734\n",
      "TRAINED FOR 159, CURRENT LOSS IS: 0.5441317941317941\n",
      "TRAINED FOR 160, CURRENT LOSS IS: 0.5444386392662255\n",
      "TRAINED FOR 161, CURRENT LOSS IS: 0.5437751903269145\n",
      "TRAINED FOR 162, CURRENT LOSS IS: 0.5428629480353618\n",
      "TRAINED FOR 163, CURRENT LOSS IS: 0.5444801048249325\n",
      "TRAINED FOR 164, CURRENT LOSS IS: 0.5442727770313978\n",
      "TRAINED FOR 165, CURRENT LOSS IS: 0.543891293891294\n",
      "TRAINED FOR 166, CURRENT LOSS IS: 0.5450523295350882\n",
      "TRAINED FOR 167, CURRENT LOSS IS: 0.5455747955747956\n",
      "TRAINED FOR 168, CURRENT LOSS IS: 0.5454421057869334\n",
      "TRAINED FOR 169, CURRENT LOSS IS: 0.5450440364233468\n",
      "TRAINED FOR 170, CURRENT LOSS IS: 0.5455001575691232\n",
      "TRAINED FOR 171, CURRENT LOSS IS: 0.5445879152775704\n",
      "TRAINED FOR 172, CURRENT LOSS IS: 0.5452264848816573\n",
      "TRAINED FOR 173, CURRENT LOSS IS: 0.5441815528022425\n",
      "TRAINED FOR 174, CURRENT LOSS IS: 0.5463958136371929\n",
      "TRAINED FOR 175, CURRENT LOSS IS: 0.5451933124346917\n",
      "TRAINED FOR 176, CURRENT LOSS IS: 0.5453757608930023\n",
      "TRAINED FOR 177, CURRENT LOSS IS: 0.5449693984176743\n",
      "TRAINED FOR 178, CURRENT LOSS IS: 0.5444966910484152\n",
      "TRAINED FOR 179, CURRENT LOSS IS: 0.5441649665787597\n",
      "TRAINED FOR 180, CURRENT LOSS IS: 0.545135260652502\n",
      "TRAINED FOR 181, CURRENT LOSS IS: 0.5449279328589673\n",
      "TRAINED FOR 182, CURRENT LOSS IS: 0.5443971737075185\n",
      "TRAINED FOR 183, CURRENT LOSS IS: 0.5422907233252061\n",
      "TRAINED FOR 184, CURRENT LOSS IS: 0.5422160853195336\n",
      "TRAINED FOR 185, CURRENT LOSS IS: 0.5429375860410343\n",
      "TRAINED FOR 186, CURRENT LOSS IS: 0.54237365444262\n",
      "TRAINED FOR 187, CURRENT LOSS IS: 0.541370187921912\n",
      "TRAINED FOR 188, CURRENT LOSS IS: 0.5413204292514637\n",
      "TRAINED FOR 189, CURRENT LOSS IS: 0.5419341195203264\n",
      "TRAINED FOR 190, CURRENT LOSS IS: 0.5421165679786369\n",
      "TRAINED FOR 191, CURRENT LOSS IS: 0.5421497404256025\n",
      "TRAINED FOR 192, CURRENT LOSS IS: 0.5422658439899819\n",
      "TRAINED FOR 193, CURRENT LOSS IS: 0.541967291967292\n",
      "TRAINED FOR 194, CURRENT LOSS IS: 0.5431946725050174\n",
      "TRAINED FOR 195, CURRENT LOSS IS: 0.5438830007795525\n",
      "TRAINED FOR 196, CURRENT LOSS IS: 0.5431946725050173\n",
      "TRAINED FOR 197, CURRENT LOSS IS: 0.5427551375827238\n",
      "TRAINED FOR 198, CURRENT LOSS IS: 0.5430039309349655\n",
      "TRAINED FOR 199, CURRENT LOSS IS: 0.5427136720240169\n",
      "TRAINED FOR 200, CURRENT LOSS IS: 0.5428463618118791\n",
      "TRAINED FOR 201, CURRENT LOSS IS: 0.5427053789122755\n",
      "TRAINED FOR 202, CURRENT LOSS IS: 0.54524307110514\n",
      "TRAINED FOR 203, CURRENT LOSS IS: 0.5442644839196564\n",
      "TRAINED FOR 204, CURRENT LOSS IS: 0.5445381566071221\n",
      "TRAINED FOR 205, CURRENT LOSS IS: 0.5451269675407607\n",
      "TRAINED FOR 206, CURRENT LOSS IS: 0.5454421057869334\n",
      "TRAINED FOR 207, CURRENT LOSS IS: 0.5451601399877263\n",
      "TRAINED FOR 208, CURRENT LOSS IS: 0.544065449237863\n",
      "TRAINED FOR 209, CURRENT LOSS IS: 0.5437171385447247\n",
      "TRAINED FOR 210, CURRENT LOSS IS: 0.5446708463949843\n",
      "TRAINED FOR 211, CURRENT LOSS IS: 0.54554162312783\n",
      "TRAINED FOR 212, CURRENT LOSS IS: 0.5436756729860178\n",
      "TRAINED FOR 213, CURRENT LOSS IS: 0.5447288981771741\n",
      "TRAINED FOR 214, CURRENT LOSS IS: 0.5446459670597602\n",
      "TRAINED FOR 215, CURRENT LOSS IS: 0.5448450017415535\n",
      "TRAINED FOR 216, CURRENT LOSS IS: 0.5453508815577781\n",
      "TRAINED FOR 217, CURRENT LOSS IS: 0.5455333300160886\n",
      "TRAINED FOR 218, CURRENT LOSS IS: 0.5455747955747956\n",
      "TRAINED FOR 219, CURRENT LOSS IS: 0.5466280207659517\n",
      "TRAINED FOR 220, CURRENT LOSS IS: 0.5459728649383823\n",
      "TRAINED FOR 221, CURRENT LOSS IS: 0.5470426763530212\n",
      "TRAINED FOR 222, CURRENT LOSS IS: 0.5469846245708314\n",
      "TRAINED FOR 223, CURRENT LOSS IS: 0.5469597452356073\n",
      "TRAINED FOR 224, CURRENT LOSS IS: 0.5465616758720208\n",
      "TRAINED FOR 225, CURRENT LOSS IS: 0.5471629264732714\n",
      "TRAINED FOR 226, CURRENT LOSS IS: 0.5470343832412798\n",
      "TRAINED FOR 227, CURRENT LOSS IS: 0.5471339005821764\n",
      "TRAINED FOR 228, CURRENT LOSS IS: 0.5468353485594866\n",
      "TRAINED FOR 229, CURRENT LOSS IS: 0.5470592625765041\n",
      "TRAINED FOR 230, CURRENT LOSS IS: 0.5490413162826956\n",
      "TRAINED FOR 231, CURRENT LOSS IS: 0.5482285913320397\n",
      "TRAINED FOR 232, CURRENT LOSS IS: 0.5478719875271599\n",
      "TRAINED FOR 233, CURRENT LOSS IS: 0.5479549186445738\n",
      "TRAINED FOR 234, CURRENT LOSS IS: 0.5477890564097461\n",
      "TRAINED FOR 235, CURRENT LOSS IS: 0.5469265727886418\n",
      "TRAINED FOR 236, CURRENT LOSS IS: 0.5473329352639698\n",
      "TRAINED FOR 237, CURRENT LOSS IS: 0.5481539533263672\n",
      "TRAINED FOR 238, CURRENT LOSS IS: 0.5467607105538141\n",
      "TRAINED FOR 239, CURRENT LOSS IS: 0.5457157784743991\n",
      "TRAINED FOR 240, CURRENT LOSS IS: 0.5459977442736064\n",
      "TRAINED FOR 241, CURRENT LOSS IS: 0.5459148131561925\n",
      "TRAINED FOR 242, CURRENT LOSS IS: 0.5461553133966928\n",
      "TRAINED FOR 243, CURRENT LOSS IS: 0.5456328473569854\n",
      "TRAINED FOR 244, CURRENT LOSS IS: 0.5454255195634505\n",
      "TRAINED FOR 245, CURRENT LOSS IS: 0.5466446069894346\n",
      "TRAINED FOR 246, CURRENT LOSS IS: 0.5457821233683303\n",
      "TRAINED FOR 247, CURRENT LOSS IS: 0.5466363138776933\n",
      "TRAINED FOR 248, CURRENT LOSS IS: 0.5455333300160886\n",
      "TRAINED FOR 249, CURRENT LOSS IS: 0.5445879152775704\n",
      "TRAINED FOR 250, CURRENT LOSS IS: 0.5449859846411571\n",
      "TRAINED FOR 251, CURRENT LOSS IS: 0.546312882519779\n",
      "TRAINED FOR 252, CURRENT LOSS IS: 0.5445381566071221\n",
      "TRAINED FOR 253, CURRENT LOSS IS: 0.5450937950937951\n",
      "TRAINED FOR 254, CURRENT LOSS IS: 0.5449279328589673\n",
      "TRAINED FOR 255, CURRENT LOSS IS: 0.5442313114726908\n",
      "TRAINED FOR 256, CURRENT LOSS IS: 0.5437503109916902\n",
      "TRAINED FOR 257, CURRENT LOSS IS: 0.5442064321374667\n",
      "TRAINED FOR 258, CURRENT LOSS IS: 0.5452928297755884\n",
      "TRAINED FOR 259, CURRENT LOSS IS: 0.5452928297755885\n",
      "TRAINED FOR 260, CURRENT LOSS IS: 0.5450191570881225\n",
      "TRAINED FOR 261, CURRENT LOSS IS: 0.5449942777528984\n",
      "TRAINED FOR 262, CURRENT LOSS IS: 0.5464206929724171\n",
      "TRAINED FOR 263, CURRENT LOSS IS: 0.5466611932129173\n",
      "TRAINED FOR 264, CURRENT LOSS IS: 0.5466363138776932\n",
      "TRAINED FOR 265, CURRENT LOSS IS: 0.5462548307375894\n",
      "TRAINED FOR 266, CURRENT LOSS IS: 0.5488837471596093\n",
      "TRAINED FOR 267, CURRENT LOSS IS: 0.5496715927750411\n",
      "TRAINED FOR 268, CURRENT LOSS IS: 0.5499037999037999\n",
      "TRAINED FOR 269, CURRENT LOSS IS: 0.5508409215305766\n",
      "TRAINED FOR 270, CURRENT LOSS IS: 0.5502769899321623\n",
      "TRAINED FOR 271, CURRENT LOSS IS: 0.5484690915725398\n",
      "TRAINED FOR 272, CURRENT LOSS IS: 0.5487012987012987\n",
      "TRAINED FOR 273, CURRENT LOSS IS: 0.5474490388283492\n",
      "TRAINED FOR 274, CURRENT LOSS IS: 0.5472500041465559\n",
      "TRAINED FOR 275, CURRENT LOSS IS: 0.5486266606956263\n",
      "TRAINED FOR 276, CURRENT LOSS IS: 0.5480793153206946\n",
      "TRAINED FOR 277, CURRENT LOSS IS: 0.5450772088703123\n",
      "TRAINED FOR 278, CURRENT LOSS IS: 0.5453342953342954\n",
      "TRAINED FOR 279, CURRENT LOSS IS: 0.5453674677812609\n",
      "TRAINED FOR 280, CURRENT LOSS IS: 0.5463958136371929\n",
      "TRAINED FOR 281, CURRENT LOSS IS: 0.5458733475974855\n",
      "TRAINED FOR 282, CURRENT LOSS IS: 0.5464953309780896\n",
      "TRAINED FOR 283, CURRENT LOSS IS: 0.5474407457166078\n",
      "TRAINED FOR 284, CURRENT LOSS IS: 0.548129073991143\n",
      "TRAINED FOR 285, CURRENT LOSS IS: 0.5475900217279528\n",
      "TRAINED FOR 286, CURRENT LOSS IS: 0.5482866431142294\n",
      "TRAINED FOR 287, CURRENT LOSS IS: 0.548129073991143\n",
      "TRAINED FOR 288, CURRENT LOSS IS: 0.5491491267353337\n",
      "TRAINED FOR 289, CURRENT LOSS IS: 0.5487842298187127\n",
      "TRAINED FOR 290, CURRENT LOSS IS: 0.5464289860841585\n",
      "TRAINED FOR 291, CURRENT LOSS IS: 0.5463460549667446\n",
      "TRAINED FOR 292, CURRENT LOSS IS: 0.5465699689837621\n",
      "TRAINED FOR 293, CURRENT LOSS IS: 0.5470675556882454\n",
      "TRAINED FOR 294, CURRENT LOSS IS: 0.5469016934534177\n",
      "TRAINED FOR 295, CURRENT LOSS IS: 0.5463875205254516\n",
      "TRAINED FOR 296, CURRENT LOSS IS: 0.5477973495214874\n",
      "TRAINED FOR 297, CURRENT LOSS IS: 0.5488588678243851\n",
      "TRAINED FOR 298, CURRENT LOSS IS: 0.5482783500024879\n",
      "TRAINED FOR 299, CURRENT LOSS IS: 0.548751057371747\n",
      "TRAINED FOR 300, CURRENT LOSS IS: 0.5480793153206946\n",
      "TRAINED FOR 301, CURRENT LOSS IS: 0.547938332421091\n",
      "TRAINED FOR 302, CURRENT LOSS IS: 0.5466363138776933\n",
      "TRAINED FOR 303, CURRENT LOSS IS: 0.546288003184555\n",
      "TRAINED FOR 304, CURRENT LOSS IS: 0.5445630359423463\n",
      "TRAINED FOR 305, CURRENT LOSS IS: 0.5442893632548805\n",
      "TRAINED FOR 306, CURRENT LOSS IS: 0.5461553133966928\n",
      "TRAINED FOR 307, CURRENT LOSS IS: 0.5462258048464945\n",
      "TRAINED FOR 308, CURRENT LOSS IS: 0.5458152958152958\n",
      "TRAINED FOR 309, CURRENT LOSS IS: 0.5459065200444511\n",
      "TRAINED FOR 310, CURRENT LOSS IS: 0.5449693984176743\n",
      "TRAINED FOR 311, CURRENT LOSS IS: 0.5440986216848287\n",
      "TRAINED FOR 312, CURRENT LOSS IS: 0.5448532948532949\n",
      "TRAINED FOR 313, CURRENT LOSS IS: 0.5454752782338989\n",
      "TRAINED FOR 314, CURRENT LOSS IS: 0.5459231062679338\n",
      "TRAINED FOR 315, CURRENT LOSS IS: 0.5457655371448475\n",
      "TRAINED FOR 316, CURRENT LOSS IS: 0.5453674677812609\n",
      "TRAINED FOR 317, CURRENT LOSS IS: 0.5459231062679338\n",
      "TRAINED FOR 318, CURRENT LOSS IS: 0.5458152958152959\n",
      "TRAINED FOR 319, CURRENT LOSS IS: 0.5465533827602793\n",
      "TRAINED FOR 320, CURRENT LOSS IS: 0.5457821233683303\n",
      "TRAINED FOR 321, CURRENT LOSS IS: 0.5459396924914166\n",
      "TRAINED FOR 322, CURRENT LOSS IS: 0.5456162611335025\n",
      "TRAINED FOR 323, CURRENT LOSS IS: 0.5448864673002604\n",
      "TRAINED FOR 324, CURRENT LOSS IS: 0.5446957257302085\n",
      "TRAINED FOR 325, CURRENT LOSS IS: 0.5455499162395714\n",
      "TRAINED FOR 326, CURRENT LOSS IS: 0.5461138478379858\n",
      "TRAINED FOR 327, CURRENT LOSS IS: 0.545392347116485\n",
      "TRAINED FOR 328, CURRENT LOSS IS: 0.5458235889270373\n",
      "TRAINED FOR 329, CURRENT LOSS IS: 0.5454338126751921\n",
      "TRAINED FOR 330, CURRENT LOSS IS: 0.544836708629812\n",
      "TRAINED FOR 331, CURRENT LOSS IS: 0.5455001575691232\n",
      "TRAINED FOR 332, CURRENT LOSS IS: 0.5458733475974855\n",
      "TRAINED FOR 333, CURRENT LOSS IS: 0.5459977442736064\n",
      "TRAINED FOR 334, CURRENT LOSS IS: 0.546246537625848\n",
      "TRAINED FOR 335, CURRENT LOSS IS: 0.5464206929724171\n",
      "TRAINED FOR 336, CURRENT LOSS IS: 0.5453011228873298\n",
      "TRAINED FOR 337, CURRENT LOSS IS: 0.5459728649383822\n",
      "TRAINED FOR 338, CURRENT LOSS IS: 0.5458484682622614\n",
      "TRAINED FOR 339, CURRENT LOSS IS: 0.5454421057869333\n",
      "TRAINED FOR 340, CURRENT LOSS IS: 0.5451020882055365\n",
      "TRAINED FOR 341, CURRENT LOSS IS: 0.545690899139175\n",
      "TRAINED FOR 342, CURRENT LOSS IS: 0.5462465376258481\n",
      "TRAINED FOR 343, CURRENT LOSS IS: 0.5465865552072449\n",
      "TRAINED FOR 344, CURRENT LOSS IS: 0.5465533827602793\n",
      "TRAINED FOR 345, CURRENT LOSS IS: 0.5459562787148994\n",
      "TRAINED FOR 346, CURRENT LOSS IS: 0.5465948483189862\n",
      "TRAINED FOR 347, CURRENT LOSS IS: 0.547979797979798\n",
      "TRAINED FOR 348, CURRENT LOSS IS: 0.5465948483189863\n",
      "TRAINED FOR 349, CURRENT LOSS IS: 0.545433812675192\n",
      "TRAINED FOR 350, CURRENT LOSS IS: 0.5455913817982784\n",
      "TRAINED FOR 351, CURRENT LOSS IS: 0.5442478976961735\n",
      "TRAINED FOR 352, CURRENT LOSS IS: 0.5444966910484152\n",
      "TRAINED FOR 353, CURRENT LOSS IS: 0.5442313114726908\n",
      "TRAINED FOR 354, CURRENT LOSS IS: 0.5440073974556733\n",
      "TRAINED FOR 355, CURRENT LOSS IS: 0.5443142425901046\n",
      "TRAINED FOR 356, CURRENT LOSS IS: 0.5444220530427427\n",
      "TRAINED FOR 357, CURRENT LOSS IS: 0.543659086762535\n",
      "TRAINED FOR 358, CURRENT LOSS IS: 0.543659086762535\n",
      "TRAINED FOR 359, CURRENT LOSS IS: 0.5435015176394485\n",
      "TRAINED FOR 360, CURRENT LOSS IS: 0.5443308288135875\n",
      "TRAINED FOR 361, CURRENT LOSS IS: 0.5447288981771741\n",
      "TRAINED FOR 362, CURRENT LOSS IS: 0.5456743129156922\n",
      "TRAINED FOR 363, CURRENT LOSS IS: 0.5442147252492079\n",
      "TRAINED FOR 364, CURRENT LOSS IS: 0.5438581214443283\n",
      "TRAINED FOR 365, CURRENT LOSS IS: 0.5430453964936724\n",
      "TRAINED FOR 366, CURRENT LOSS IS: 0.5442478976961735\n",
      "TRAINED FOR 367, CURRENT LOSS IS: 0.5458733475974855\n",
      "TRAINED FOR 368, CURRENT LOSS IS: 0.5466197276542104\n",
      "TRAINED FOR 369, CURRENT LOSS IS: 0.5461055547262444\n",
      "TRAINED FOR 370, CURRENT LOSS IS: 0.5468104692242624\n",
      "TRAINED FOR 371, CURRENT LOSS IS: 0.5468104692242624\n",
      "TRAINED FOR 372, CURRENT LOSS IS: 0.5462548307375894\n",
      "TRAINED FOR 373, CURRENT LOSS IS: 0.5462299514023652\n",
      "TRAINED FOR 374, CURRENT LOSS IS: 0.5468519347829692\n",
      "TRAINED FOR 375, CURRENT LOSS IS: 0.545989451161865\n",
      "TRAINED FOR 376, CURRENT LOSS IS: 0.5461055547262443\n",
      "TRAINED FOR 377, CURRENT LOSS IS: 0.545284536663847\n",
      "TRAINED FOR 378, CURRENT LOSS IS: 0.5459728649383822\n",
      "TRAINED FOR 379, CURRENT LOSS IS: 0.5458650544857441\n",
      "TRAINED FOR 380, CURRENT LOSS IS: 0.5445215703836392\n",
      "TRAINED FOR 381, CURRENT LOSS IS: 0.5448615879650363\n",
      "TRAINED FOR 382, CURRENT LOSS IS: 0.5443308288135874\n",
      "TRAINED FOR 383, CURRENT LOSS IS: 0.5431532069463104\n",
      "TRAINED FOR 384, CURRENT LOSS IS: 0.5452347779933986\n",
      "TRAINED FOR 385, CURRENT LOSS IS: 0.5458567613740027\n",
      "TRAINED FOR 386, CURRENT LOSS IS: 0.5458567613740027\n",
      "TRAINED FOR 387, CURRENT LOSS IS: 0.5464289860841585\n",
      "TRAINED FOR 388, CURRENT LOSS IS: 0.5460392098323132\n",
      "TRAINED FOR 389, CURRENT LOSS IS: 0.5458982269327097\n",
      "TRAINED FOR 390, CURRENT LOSS IS: 0.545690899139175\n",
      "TRAINED FOR 391, CURRENT LOSS IS: 0.5468353485594866\n",
      "TRAINED FOR 392, CURRENT LOSS IS: 0.5473412283757112\n",
      "TRAINED FOR 393, CURRENT LOSS IS: 0.5466280207659518\n",
      "TRAINED FOR 394, CURRENT LOSS IS: 0.5466943656598829\n",
      "TRAINED FOR 395, CURRENT LOSS IS: 0.5462797100728135\n",
      "TRAINED FOR 396, CURRENT LOSS IS: 0.5463958136371929\n",
      "TRAINED FOR 397, CURRENT LOSS IS: 0.5459148131561925\n",
      "TRAINED FOR 398, CURRENT LOSS IS: 0.5443888805957772\n",
      "TRAINED FOR 399, CURRENT LOSS IS: 0.5440488630143803\n",
      "TRAINED FOR 400, CURRENT LOSS IS: 0.5442727770313978\n",
      "TRAINED FOR 401, CURRENT LOSS IS: 0.5432195518402415\n",
      "TRAINED FOR 402, CURRENT LOSS IS: 0.5437668972151731\n",
      "TRAINED FOR 403, CURRENT LOSS IS: 0.5439493456734836\n",
      "TRAINED FOR 404, CURRENT LOSS IS: 0.5450108639763812\n",
      "TRAINED FOR 405, CURRENT LOSS IS: 0.5460723822792789\n",
      "TRAINED FOR 406, CURRENT LOSS IS: 0.5443971737075186\n",
      "TRAINED FOR 407, CURRENT LOSS IS: 0.5433273622928796\n",
      "TRAINED FOR 408, CURRENT LOSS IS: 0.544430346154484\n",
      "TRAINED FOR 409, CURRENT LOSS IS: 0.5463792274137101\n",
      "TRAINED FOR 410, CURRENT LOSS IS: 0.5459065200444511\n",
      "TRAINED FOR 411, CURRENT LOSS IS: 0.5448201224063293\n",
      "TRAINED FOR 412, CURRENT LOSS IS: 0.5447537775123982\n",
      "TRAINED FOR 413, CURRENT LOSS IS: 0.544728898177174\n",
      "TRAINED FOR 414, CURRENT LOSS IS: 0.5458567613740027\n",
      "TRAINED FOR 415, CURRENT LOSS IS: 0.545690899139175\n",
      "TRAINED FOR 416, CURRENT LOSS IS: 0.5453094159990711\n",
      "TRAINED FOR 417, CURRENT LOSS IS: 0.5442478976961735\n",
      "TRAINED FOR 418, CURRENT LOSS IS: 0.5446625532832429\n",
      "TRAINED FOR 419, CURRENT LOSS IS: 0.5444054668192599\n",
      "TRAINED FOR 420, CURRENT LOSS IS: 0.5439410525617423\n",
      "TRAINED FOR 421, CURRENT LOSS IS: 0.545135260652502\n",
      "TRAINED FOR 422, CURRENT LOSS IS: 0.5453508815577781\n",
      "TRAINED FOR 423, CURRENT LOSS IS: 0.546503624089831\n",
      "TRAINED FOR 424, CURRENT LOSS IS: 0.5466611932129173\n",
      "TRAINED FOR 425, CURRENT LOSS IS: 0.5472997628170042\n",
      "TRAINED FOR 426, CURRENT LOSS IS: 0.5478222288567116\n",
      "TRAINED FOR 427, CURRENT LOSS IS: 0.5460392098323132\n",
      "TRAINED FOR 428, CURRENT LOSS IS: 0.5453923471164851\n",
      "TRAINED FOR 429, CURRENT LOSS IS: 0.5451186744290193\n",
      "TRAINED FOR 430, CURRENT LOSS IS: 0.5447288981771741\n",
      "TRAINED FOR 431, CURRENT LOSS IS: 0.5457738302565889\n",
      "TRAINED FOR 432, CURRENT LOSS IS: 0.5454669851221575\n",
      "TRAINED FOR 433, CURRENT LOSS IS: 0.5466860725481415\n",
      "TRAINED FOR 434, CURRENT LOSS IS: 0.5467690036655554\n",
      "TRAINED FOR 435, CURRENT LOSS IS: 0.5460889685027616\n",
      "TRAINED FOR 436, CURRENT LOSS IS: 0.5457240715861406\n",
      "TRAINED FOR 437, CURRENT LOSS IS: 0.5461884858436582\n",
      "TRAINED FOR 438, CURRENT LOSS IS: 0.5453342953342953\n",
      "TRAINED FOR 439, CURRENT LOSS IS: 0.5452016055464332\n",
      "TRAINED FOR 440, CURRENT LOSS IS: 0.5440571561261216\n",
      "TRAINED FOR 441, CURRENT LOSS IS: 0.5445298634953808\n",
      "TRAINED FOR 442, CURRENT LOSS IS: 0.544471811713191\n",
      "TRAINED FOR 443, CURRENT LOSS IS: 0.5455416231278302\n",
      "TRAINED FOR 444, CURRENT LOSS IS: 0.5454503988986747\n",
      "TRAINED FOR 445, CURRENT LOSS IS: 0.5451269675407606\n",
      "TRAINED FOR 446, CURRENT LOSS IS: 0.5450606226468295\n",
      "TRAINED FOR 447, CURRENT LOSS IS: 0.5461304340614686\n",
      "TRAINED FOR 448, CURRENT LOSS IS: 0.5458318820387786\n",
      "TRAINED FOR 449, CURRENT LOSS IS: 0.5460309167205719\n",
      "TRAINED FOR 450, CURRENT LOSS IS: 0.5453260022225539\n",
      "TRAINED FOR 451, CURRENT LOSS IS: 0.5444801048249324\n",
      "TRAINED FOR 452, CURRENT LOSS IS: 0.5454006402282263\n",
      "TRAINED FOR 453, CURRENT LOSS IS: 0.5451933124346917\n",
      "TRAINED FOR 454, CURRENT LOSS IS: 0.5455333300160886\n",
      "TRAINED FOR 455, CURRENT LOSS IS: 0.5458318820387786\n",
      "TRAINED FOR 456, CURRENT LOSS IS: 0.5462548307375894\n",
      "TRAINED FOR 457, CURRENT LOSS IS: 0.545989451161865\n",
      "TRAINED FOR 458, CURRENT LOSS IS: 0.5458733475974855\n",
      "TRAINED FOR 459, CURRENT LOSS IS: 0.5467772967772968\n",
      "TRAINED FOR 460, CURRENT LOSS IS: 0.5480793153206946\n",
      "TRAINED FOR 461, CURRENT LOSS IS: 0.5471007281352109\n",
      "TRAINED FOR 462, CURRENT LOSS IS: 0.5479217461976083\n",
      "TRAINED FOR 463, CURRENT LOSS IS: 0.546462158531124\n",
      "TRAINED FOR 464, CURRENT LOSS IS: 0.5451684330994676\n",
      "TRAINED FOR 465, CURRENT LOSS IS: 0.546055796055796\n",
      "TRAINED FOR 466, CURRENT LOSS IS: 0.5464953309780896\n",
      "TRAINED FOR 467, CURRENT LOSS IS: 0.546652900101176\n",
      "TRAINED FOR 468, CURRENT LOSS IS: 0.5461304340614684\n",
      "TRAINED FOR 469, CURRENT LOSS IS: 0.545649433580468\n",
      "TRAINED FOR 470, CURRENT LOSS IS: 0.5450108639763812\n",
      "TRAINED FOR 471, CURRENT LOSS IS: 0.545284536663847\n",
      "TRAINED FOR 472, CURRENT LOSS IS: 0.5461718996201754\n",
      "TRAINED FOR 473, CURRENT LOSS IS: 0.5459811580501235\n",
      "TRAINED FOR 474, CURRENT LOSS IS: 0.5472831765935214\n",
      "TRAINED FOR 475, CURRENT LOSS IS: 0.5474739181635733\n",
      "TRAINED FOR 476, CURRENT LOSS IS: 0.5463045894080376\n",
      "TRAINED FOR 477, CURRENT LOSS IS: 0.5465202103133138\n",
      "TRAINED FOR 478, CURRENT LOSS IS: 0.5467275381068484\n",
      "TRAINED FOR 479, CURRENT LOSS IS: 0.5473661077109353\n",
      "TRAINED FOR 480, CURRENT LOSS IS: 0.5475651423927286\n",
      "TRAINED FOR 481, CURRENT LOSS IS: 0.5462962962962963\n",
      "TRAINED FOR 482, CURRENT LOSS IS: 0.547316349040487\n",
      "TRAINED FOR 483, CURRENT LOSS IS: 0.5460889685027616\n",
      "TRAINED FOR 484, CURRENT LOSS IS: 0.5456411404687267\n",
      "TRAINED FOR 485, CURRENT LOSS IS: 0.5459645718266408\n",
      "TRAINED FOR 486, CURRENT LOSS IS: 0.5455499162395714\n",
      "TRAINED FOR 487, CURRENT LOSS IS: 0.544770363735881\n",
      "TRAINED FOR 488, CURRENT LOSS IS: 0.5443308288135874\n",
      "TRAINED FOR 489, CURRENT LOSS IS: 0.5436673798742764\n",
      "TRAINED FOR 490, CURRENT LOSS IS: 0.5439410525617422\n",
      "TRAINED FOR 491, CURRENT LOSS IS: 0.5438166558856214\n",
      "TRAINED FOR 492, CURRENT LOSS IS: 0.543144913834569\n",
      "TRAINED FOR 493, CURRENT LOSS IS: 0.5430122240467068\n",
      "TRAINED FOR 494, CURRENT LOSS IS: 0.5440405699026388\n",
      "TRAINED FOR 495, CURRENT LOSS IS: 0.5445962083893119\n",
      "TRAINED FOR 496, CURRENT LOSS IS: 0.5446376739480188\n",
      "TRAINED FOR 497, CURRENT LOSS IS: 0.5444635186014497\n",
      "TRAINED FOR 498, CURRENT LOSS IS: 0.5442064321374667\n",
      "TRAINED FOR 499, CURRENT LOSS IS: 0.54410691479657\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m n_epochs: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m early_stop(val_losses, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m---> 36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     cv_loss \u001b[38;5;241m=\u001b[39m get_cv_auc()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     38\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(cv_loss)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "Cell \u001b[1;32mIn[53], line 19\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m Tensor(y_train_new[samples], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(X_batch)\u001b[38;5;241m.\u001b[39mcross_entropy(y_batch)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\nn\\optim.py:34\u001b[0m, in \u001b[0;36mOptimizer.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m  Performs a single optimization step.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m   \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\tensor.py:3520\u001b[0m, in \u001b[0;36m_metadata_wrapper.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 3520\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3522\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   3523\u001b[0m     caller_frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(frame \u001b[38;5;241m:=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\tensor.py:223\u001b[0m, in \u001b[0;36mTensor.realize\u001b[1;34m(self, do_update_stats, *lst)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrealize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mlst:Tensor, do_update_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    222\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Triggers the computation needed to create these Tensor(s).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m   run_schedule(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_with_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlst\u001b[49m\u001b[43m)\u001b[49m, do_update_stats\u001b[38;5;241m=\u001b[39mdo_update_stats)\n\u001b[0;32m    224\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\tensor.py:3520\u001b[0m, in \u001b[0;36m_metadata_wrapper.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 3520\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _METADATA\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3522\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m TRACEMETA \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   3523\u001b[0m     caller_frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(frame \u001b[38;5;241m:=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\tensor.py:212\u001b[0m, in \u001b[0;36mTensor.schedule_with_vars\u001b[1;34m(self, *lst)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mschedule_with_vars\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mlst:Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[ScheduleItem], Dict[Variable, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m  Creates the schedule needed to realize these Tensor(s), with Variables.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m  NOTE: A Tensor can only be scheduled once.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m   schedule, var_vals \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_schedule_with_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlbs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mlst\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m memory_planner(schedule), var_vals\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\ops.py:666\u001b[0m, in \u001b[0;36mtrack_rewrites.<locals>._decorator.<locals>.__wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m named: _rewrite_cnt[func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m _rewrite_cnt\u001b[38;5;241m.\u001b[39msetdefault(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    665\u001b[0m   rewrite_stack\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(n\u001b[38;5;241m:=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_rewrite_cnt[n]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m named \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m, []))\n\u001b[1;32m--> 666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m: \u001b[38;5;66;03m# NOTE: save everything in the stack\u001b[39;00m\n\u001b[0;32m    668\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m TRACK_MATCH_STATS \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m: contexts\u001b[38;5;241m.\u001b[39mappend(rewrite_stack\u001b[38;5;241m.\u001b[39mpop())\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\engine\\schedule.py:249\u001b[0m, in \u001b[0;36mcreate_schedule_with_vars\u001b[1;34m(outs)\u001b[0m\n\u001b[0;32m    247\u001b[0m graph_rewrite(big_graph, break_sched, realizes)\n\u001b[0;32m    248\u001b[0m assigned \u001b[38;5;241m=\u001b[39m {ubuf \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m assigns \u001b[38;5;28;01mif\u001b[39;00m (ubuf\u001b[38;5;241m:=\u001b[39mctx\u001b[38;5;241m.\u001b[39mbuf_uops\u001b[38;5;241m.\u001b[39mget(x\u001b[38;5;241m.\u001b[39mbuffer)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m--> 249\u001b[0m small_graphs \u001b[38;5;241m=\u001b[39m [full_ast_rewrite(UOp\u001b[38;5;241m.\u001b[39msink(\u001b[38;5;241m*\u001b[39m(realizes[ctx\u001b[38;5;241m.\u001b[39mbuf_uops[b]] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m stores)),\n\u001b[0;32m    250\u001b[0m                                  ctx\u001b[38;5;241m.\u001b[39mvar_vals, assigned, ctx\u001b[38;5;241m.\u001b[39mubuf_metadata) \u001b[38;5;28;01mfor\u001b[39;00m stores \u001b[38;5;129;01min\u001b[39;00m store_groups]\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# do BFS\u001b[39;00m\n\u001b[0;32m    253\u001b[0m prescheduled \u001b[38;5;241m=\u001b[39m [ScheduleItem(u, \u001b[38;5;28mtuple\u001b[39m(b \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m c\u001b[38;5;241m.\u001b[39mbufs \u001b[38;5;28;01mif\u001b[39;00m (b\u001b[38;5;241m:=\u001b[39mctx\u001b[38;5;241m.\u001b[39muop_bufs[u])\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    254\u001b[0m                          \u001b[38;5;28mtuple\u001b[39m(c\u001b[38;5;241m.\u001b[39mmetadata), \u001b[38;5;28mtuple\u001b[39m(c\u001b[38;5;241m.\u001b[39massign_preloads)) \u001b[38;5;28;01mfor\u001b[39;00m u,c \u001b[38;5;129;01min\u001b[39;00m small_graphs]\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\engine\\schedule.py:249\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    247\u001b[0m graph_rewrite(big_graph, break_sched, realizes)\n\u001b[0;32m    248\u001b[0m assigned \u001b[38;5;241m=\u001b[39m {ubuf \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m assigns \u001b[38;5;28;01mif\u001b[39;00m (ubuf\u001b[38;5;241m:=\u001b[39mctx\u001b[38;5;241m.\u001b[39mbuf_uops\u001b[38;5;241m.\u001b[39mget(x\u001b[38;5;241m.\u001b[39mbuffer)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m--> 249\u001b[0m small_graphs \u001b[38;5;241m=\u001b[39m [\u001b[43mfull_ast_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUOp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrealizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf_uops\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massigned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mubuf_metadata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m stores \u001b[38;5;129;01min\u001b[39;00m store_groups]\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# do BFS\u001b[39;00m\n\u001b[0;32m    253\u001b[0m prescheduled \u001b[38;5;241m=\u001b[39m [ScheduleItem(u, \u001b[38;5;28mtuple\u001b[39m(b \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m c\u001b[38;5;241m.\u001b[39mbufs \u001b[38;5;28;01mif\u001b[39;00m (b\u001b[38;5;241m:=\u001b[39mctx\u001b[38;5;241m.\u001b[39muop_bufs[u])\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    254\u001b[0m                          \u001b[38;5;28mtuple\u001b[39m(c\u001b[38;5;241m.\u001b[39mmetadata), \u001b[38;5;28mtuple\u001b[39m(c\u001b[38;5;241m.\u001b[39massign_preloads)) \u001b[38;5;28;01mfor\u001b[39;00m u,c \u001b[38;5;129;01min\u001b[39;00m small_graphs]\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\engine\\schedule.py:212\u001b[0m, in \u001b[0;36mfull_ast_rewrite\u001b[1;34m(pre, var_vals, assigned, ubuf_metadata)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycle detected in kernel.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mhelp: use .contiguous() to break the part loading pre-assign \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into a different kernel.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# do movementops\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m sink \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43msink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_left\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_right\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# convert to AST\u001b[39;00m\n\u001b[0;32m    214\u001b[0m sink \u001b[38;5;241m=\u001b[39m graph_rewrite(graph_rewrite(sink, to_si, ctx), append_bufs, ctx)\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\ops.py:736\u001b[0m, in \u001b[0;36mgraph_rewrite\u001b[1;34m(sink, pm, ctx)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRACK_MATCH_STATS \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rewrite_stack) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    735\u001b[0m   rewrite_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(TrackedRewriteContext(((frm\u001b[38;5;241m:=\u001b[39msys\u001b[38;5;241m.\u001b[39m_getframe(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_filename, frm\u001b[38;5;241m.\u001b[39mf_lineno), sink))\n\u001b[1;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRewriteContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43msink\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\ops.py:728\u001b[0m, in \u001b[0;36mRewriteContext.rewrite\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrewrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, n:UOp) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m UOp:\n\u001b[0;32m    727\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (rn \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace\u001b[38;5;241m.\u001b[39mget(n)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m rn\n\u001b[1;32m--> 728\u001b[0m   new_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m   new_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpm\u001b[38;5;241m.\u001b[39mrewrite(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx) \u001b[38;5;28;01mif\u001b[39;00m new_src \u001b[38;5;241m==\u001b[39m n\u001b[38;5;241m.\u001b[39msrc \u001b[38;5;28;01melse\u001b[39;00m UOp(n\u001b[38;5;241m.\u001b[39mop, n\u001b[38;5;241m.\u001b[39mdtype, new_src, n\u001b[38;5;241m.\u001b[39marg)\n\u001b[0;32m    730\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace[n] \u001b[38;5;241m=\u001b[39m ret \u001b[38;5;241m=\u001b[39m n \u001b[38;5;28;01mif\u001b[39;00m new_n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewrite(new_n)\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\ops.py:729\u001b[0m, in \u001b[0;36mRewriteContext.rewrite\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (rn \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace\u001b[38;5;241m.\u001b[39mget(n)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m rn\n\u001b[0;32m    728\u001b[0m new_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewrite, n\u001b[38;5;241m.\u001b[39msrc))\n\u001b[1;32m--> 729\u001b[0m new_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m new_src \u001b[38;5;241m==\u001b[39m n\u001b[38;5;241m.\u001b[39msrc \u001b[38;5;28;01melse\u001b[39;00m UOp(n\u001b[38;5;241m.\u001b[39mop, n\u001b[38;5;241m.\u001b[39mdtype, new_src, n\u001b[38;5;241m.\u001b[39marg)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace[n] \u001b[38;5;241m=\u001b[39m ret \u001b[38;5;241m=\u001b[39m n \u001b[38;5;28;01mif\u001b[39;00m new_n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewrite(new_n)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\ops.py:643\u001b[0m, in \u001b[0;36mPatternMatcher.rewrite\u001b[1;34m(self, uop, ctx)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p,fxn,early_reject \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdict\u001b[38;5;241m.\u001b[39mget((uop\u001b[38;5;241m.\u001b[39mop, uop\u001b[38;5;241m.\u001b[39marg), []) \u001b[38;5;241m+\u001b[39m ([] \u001b[38;5;28;01mif\u001b[39;00m uop\u001b[38;5;241m.\u001b[39marg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdict\u001b[38;5;241m.\u001b[39mget((uop\u001b[38;5;241m.\u001b[39mop, \u001b[38;5;28;01mNone\u001b[39;00m), [])):\n\u001b[0;32m    642\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m early_reject\u001b[38;5;241m.\u001b[39missubset(ler): \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 643\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (ret\u001b[38;5;241m:=\u001b[39m(fxn(ctx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmatch) \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m fxn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmatch))) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Arjun Sarao\\TabTransformer-tinygrad\\venv\\lib\\site-packages\\tinygrad\\ops.py:600\u001b[0m, in \u001b[0;36mUPat.match\u001b[1;34m(self, uop, store)\u001b[0m\n\u001b[0;32m    598\u001b[0m stores, new_stores \u001b[38;5;241m=\u001b[39m [store\u001b[38;5;241m.\u001b[39mcopy()], []\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uu, vv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(uop\u001b[38;5;241m.\u001b[39msrc, vp):\n\u001b[1;32m--> 600\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stores: \u001b[43mnew_stores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m   stores, new_stores \u001b[38;5;241m=\u001b[39m new_stores, []\n\u001b[0;32m    602\u001b[0m res\u001b[38;5;241m.\u001b[39mextend(stores)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MLP(l=X_train_new.shape[1])\n",
    "optim = nn.optim.AdamW(nn.state.get_parameters(model))\n",
    "\n",
    "def early_stop(losses: List[float], patience: int) -> bool:\n",
    "    if len(losses) < 15:\n",
    "        return False\n",
    "    else:\n",
    "        return all(a > b for a,b in pairwise(losses[-patience:]))\n",
    "\n",
    "@Tensor.train()\n",
    "def train_step() -> Tensor:\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    samples = np.random.randint(0, X_train_new.shape[0], 128)\n",
    "    X_batch = Tensor(X_train_new[samples], dtype=\"float32\")\n",
    "    y_batch = Tensor(y_train_new[samples], dtype=\"float32\")\n",
    "\n",
    "    loss = model(X_batch).cross_entropy(y_batch).backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "@Tensor.test()\n",
    "def get_cv_auc() -> float:\n",
    "    y_pred = model(Tensor(X_val_new, dtype=\"float32\"))\n",
    "    \n",
    "    y_true = y_val_new.astype(\"float32\")\n",
    "    auc = roc_auc_score(y_true, y_pred.numpy())\n",
    "    \n",
    "    return auc\n",
    "\n",
    "# Keep training until 15 consecutive cross-validation losses show a positive increase.\n",
    "# Also add \n",
    "val_losses: List[float] = []\n",
    "n_epochs: int = 0\n",
    "while not early_stop(val_losses, patience=15):\n",
    "    loss = train_step()\n",
    "    cv_loss = get_cv_auc().item()\n",
    "    val_losses.append(cv_loss)\n",
    "    n_epochs += 1\n",
    "    print(f\"TRAINED FOR {n_epochs}, CURRENT LOSS IS: {cv_loss}\")\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(val_losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
